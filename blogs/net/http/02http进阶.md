---
title: HTTP 进阶
date: 2021-1-18
categories:
 - 网络协议
---

#### HTTP 实体数据

HTTP 支持多种数据格式，但是要怎么知道是哪种数据格式呢？HTTP 使用了 **”多媒体邮件扩展“ （Multipurpose Internet Mail Extensions）** 这个标准规范中的一部分作为标识 body 数据类型。经常见到的类型有：

1. text : 即文本格式的可读数据，text/html 表示超文本文档；text/plain 表示纯文档；text/css 样式表等
2. image: 即图像文件，例如 image/png，image/gif，image/jpeg
3. audio/video: 音频和视频数据，例如 audio/mpeg，video/mp4
4. application: 数据格式不固定可能是文本也可能是二进制数据，必须由上层应用程序来解释。常见的有 application/json，application/javascript，application/pdf等，例外如果实在不知道是什么类型，就会是 application/octet-stream，即不透明的二进制数据。

仅有数据格式还不够，HTTP为了在传输过程中节省带宽，还会压缩数据。还需要一个 "Encoding type"，常见的有以下几种：

1. gzip: GNU zip 压缩格式，也是互联网上最流行的压缩格式
2. deflate: zlib (deflate) 压缩格式，流行程度仅次于 gzip
3. br: 一种专门为 HTTP 优化的新压缩算法 （Brotil）

**数据类型**

HTTP 协议定义了两个 Accept 请求头和两个 Content 响应头，用于客户端和服务端进行 “内容协商”。客户端在 Accept 头告诉服务器希望接收到什么样的数据，服务器在 Content 头里告诉客户端实际发送了什么数据。

**Accept** 字段标记的是客户端可理解的 MIME type，可以用 **“,”** 做分隔列出多种类型，让服务器有更多选择的余地。

```
Accept: text/plain,text/html,application/json,image/png
```

服务器在响应报文的头字段 **Content-Type** 中告诉客户端实体数据的实际类型

```
Content-Type: text/html
```

**Accept-Encoding** 字段标记的是客户端支持的压缩格式

```
Accept-Encoding: gzip, deflate, br
```

**Content-Encoding** 表示的是服务器实际使用的压缩格式

```
Content-Encoding: gzip
```

**语言类型和编码**

不同国家地区使用的自然语言不同，怎么让浏览器显示出每个地区都可以理解阅读的语言文字呢？这实际上就是解决国际化问题，HTTP 引入了语言类型和字符集。

**Accept-Language** 标记了客户端可理解的自然语言，用 **"-"** 分隔而不是用 **"/"** 

```
Accept-Language: zh-CN,zh,en
```

相应的服务端响应头中用 **Content-Language** 指明实体数据的语言类型

```
Content-Language: zh-CN
```

字符集使用的请求头字段是 **"Accept-Charset"** ，但是响应头里没有对应的Content-Charset，而是在 **Content-Type** 字段后面 用 **"charset=xxx"** 来表示

```
Accept-Charset: gbk,utf-8
Content-Type: text/html;charset=utf-8
```

**内容协商的质量值**

在 HTTP 协议里用 Accept、Accept-Encoding、Accept-Language 等请求头字段进行内容协商的时候，还可以用一种特殊的“q”参数表示权重来设定优先级，这里的“q”是“quality factor”的意思。

权重的最大值是 **1**，最小值是 0.01，默认值是 **1**，如果值是 **0** 就表示拒绝。具体的形式是在数据类型或语言代码后面加一个“;”，然后是“q=value”

```
Accept: text/html,application/xml;q=0.9,*/*;q=0.8
```

**内容协商的结果**

内容协商的结果是不透明的，有的时候服务器会在响应头字段里加 **Vary** 字段表示内容协商参考的请求头字段

```
Vary: Accept-Encoding,Accept
```

这个 Vary 字段表示服务器依据了 Accept-Encoding、User-Agent 和 Accept 这三个头字段，然后决定了发回的响应报文。

Vary 字段可以认为是响应报文的一个特殊的“版本标记”。每当 Accept 等请求头变化时，Vary 也会随着响应报文一起变化。也就是说，同一个 URI 可能会有多个不同的“版本”，主要用在传输链路中间的代理服务器实现缓存服务。

#### HTTP 处理大文件传输

对于几百M 甚至 几G的大文件一口气传输过来是不现实的，会等待很长的时间。那么如何在有限的带宽下高效快捷的传输这些大文件呢？

**数据压缩**

可以将数据经过压缩之后再传输。但是这个方法有缺陷：gzip 对于文本文件有较好的压缩率，但是对于图片、音频视频等已经经过高度压缩的数据就没有办法了。

**分块传输**

将大文件分成多个小块，把这些小块发给浏览器，浏览器再进行组装。这种思想再 HTTP 里的实现就是 **”chunked"** 分块传输，响应报文里面用 **“Transfer-Encoding：chunked"** 来表示报文里 body 数据不是一次性发过来的，而是分成多个块（chunked）发送过来。

**“Transfer-Encoding: chunked” **和 **“Content-Length”**这两个字段是**互斥的**，也就是说响应报文里这两个字段不能同时出现，一个响应报文的传输要么是长度已知，要么是长度未知。

分块传输的编码规则：

1. 每个分块包含两部分：长度头和数据块
2. 长度头用 **16进制的数字** 表示长度，以CRLF （回车换行，即 \r\n）结尾
3. 数据块紧跟在长度头后面，最后也用 CRLF 结尾，数据不包括CRLF
4. 最后用一个长度为 0 的块表示结束，即 **”0\r\n\r\n"**

**范围请求**

有了分块传输，服务器就可以轻松的收发大文件了，但是对于想要获取大文件的部分数据的场景时，例如观看视频时想要拖动进度条快进几分钟，这个时候分块传输是不能处理的。

为了满足这样的需求，HTTP 允许客户端再请求头使用专门的字段来表示只获取文件的一部分，即 “**范围请求**”。但是范围请求不是 WEB 服务器必备的能力，可以实现也可以不实现。所以服务器必须在响应头里加上 **"Accept-Ranges: bytes"** 来表示自己是支持范围请求的。

对于不支持范围请求的服务器，可以发送 **"Accept-Ranges: none"** 或者干脆不发送该字段，这样客户端就会认为服务器不支持范围请求，老老实实收发整块文件。

请求头 **Range** 是 HTTP 范围请求的专门字段，格式为 **bytes=x-y**，x 和 y 指的是以 **字节** 为单位的请求范围。

注意 x 和 y 表示的是偏移量，范围必须从 0 开始计数。如前十个字节：“0-9”

起点x 和 终点y 也可以省略，这样能够很方便的表示正数或倒数的范围：

- “0-” 表示从文档起点到文档终点，相当于整个文件
- "10-" 表示从第10个字节开始到文档终点
- “-1” 表示文档最后一个字节
- “-10”表示文档末尾的10个字节

服务器接收到 **Range** 字段后首先需要检查范围是否合法，如果超出范围会返回状态码 **416**，如果合法服务器就会根据偏移量读取文件片段，返回状态码 **206**，表示body 数据是原数据的一部分。同时在要在响应头字段 **Content-Range** 中告诉片段实际偏移量和总数据大小，格式为 **”bytes x-y/length**，例如对于原数据为100字节大小的 “0-10”的范围请求，值就是 “bytes 0-10/100"

**多段数据**

范围请求还可以同时请求多个片段，在 Range 头里加多个 ”x-y“，这种情况需要使用一种特殊的 MIME 类型：**“multipart/byteranges”** ，表示报文的body 是由多段字节序列组成的，并且还要用一个参数 **boundary=xxx**, 给出段之间的分隔标记。

每一个分段必须以**“- -boundary”**开始（前面加两个“-”），之后要用**“Content-Type”**和**“Content-Range”**标记这段数据的类型和所在范围，然后就像普通的响应头一样以回车换行结束，再加上分段数据，最后用一个“**- -boundary- -**”（前后各有两个“-”）表示所有的分段结束。

例如：

请求

```
GET /16-2 HTTP/1.1
Host: www.chrono.com
Range: bytes=0-9, 20-29
```

响应

```
HTTP/1.1 206 Partial Content
Content-Type: multipart/byteranges; boundary=00000000001
Content-Length: 189
Connection: keep-alive
Accept-Ranges: bytes
 
 
--00000000001
Content-Type: text/plain
Content-Range: bytes 0-9/96
 
// this is
--00000000001
Content-Type: text/plain
Content-Range: bytes 20-29/96
 
ext json d
--00000000001--
```

#### HTTP 连接管理

HTTP 最初（0.9/1.0）整个连接很短暂，发送请求，接收到请求之后连接就会关闭。这样每次请求都需要进行 tcp 三次握手，四次挥手，开销太大。于是提出了 **长连接**。HTTP 1.1版本中的连接都会默认开启长连接，只要 HTTP 向服务器发起了第一次请求，后续的请求都会重复利用这个连接。

当然我们也可以在 请求头里明确要求使用长连接的机制。这个头字段是 **Connection**，值是 **keep-alive**。不过不管客户端是否显示要求启用长连接，如果服务端支持长连接，都会在响应头里加上 **Connection: keep-alive** 字段告诉客户端是支持长连接的。

不过长连接也不能一直保持连接下去，这样如果有大量的长连接只连不发，很快就会耗尽服务器资源，因此需要在适当的时候关闭。

客户端可以在请求头中加上 **Connection: close** 字段表示这次通信后关闭连接。服务器收到这个字段之后就知道客户端要主动关闭连接，于是也在响应头中加上这个字段，发送之后断开连接。

**队头阻塞**

**队头阻塞** 与长连接和短连接无关，是由于 HTTP 的请求-应答 模型导致的。

因为 HTTP 要求必须 **”一收一发“**，这就形成了一个先进先出的串行队列，队列中的请求没有轻重缓急的优先关系，排在最前面的请求优先处理，处理完之后才能处理下一个请求。如果队首的请求太慢，就会阻塞后面的请求处理。

对此，HTTP 使用了以下解决方案

1. **并发连接** ：也就是同时对一个域名发起多个长连接，用数量解决质量问题。但是不能建立很多连接，现在浏览器一般限制在 6 ~8个，chrome 是 6 个。
2. **域名分片** ：多开几个域名，而这些域名又指向同一台服务器，这样实际的连接数量又上去了。

#### HTTP Cookie

HTTP 是一个无状态协议，但是有时候需要保存一些状态，为此引入了 **cookie**。

Cookie 本质上就是浏览器存储的一个很小的文本信息，以key-value的方式存储。服务器通过 **Set-Cookie** 头字段写入cookie，浏览器收到响应报文后会把 cookie 保存下来，下次请求的时候会自动带上，放在请求头 **Cookie** 字段里。服务器可以在头字段添加多个 **Set-Cookie** 写入多个 cookie，浏览器发送时不需要发送多个 **Cookie** 字段，只需要在一行里用 **“；”** 隔开

**cookie 的属性**

cookie 实际上就是服务器委托浏览器存储在客户端里的一些数据，通常这些数据都会记录用户的相关识别信息，因此需要使用一些手段来保护 cookie ，防止外泄或窃取。

1. **设置生命周期**：Cookie 可以设置有效期，超过期限浏览器就会把它从存储中删除，不会发送给服务端。

   有效期可以使用 **Max-Age** 和 **Expires** 来设置

   **Expires** ，即过期时间。用的是绝对事件点，可以理解为截至日期；**Max-Age** ，失效时长，使用的是相对时间，单位为 **秒**，浏览器收到报文的时间加上 Max-Age 的时间，就是失效的时间。

   当 **Expires** 和 **Max-Age** 同时出现时，浏览器会优先考虑 Max-Age

2. **设置作用域**：让浏览器只发给特定的服务器和 URI。

   **Domain** 和 **Path** 可以指定 cookie 所属的域名和路径。在发送请求之前，浏览器会提取当前 URL 中的 host 和 path 部分，对比 cookie 的 属性，如果不匹配就不会发送 cookie

3. **安全**：

   js 可以通过 document.cookie 读取 cookie 的值，容易收到 **XSS 攻击（"跨站脚本攻击"）** ，可以设置 **HttpOnly**，告诉浏览器此 cookie 只能通过 HTTP 协议传输，禁止其他方式访问。

   另一个属性 **SameSite**，可以防范 **XSRF 攻击 （”跨域请求伪造“）**，共有三种属性

   1. **strict** : 这个最为严格，禁止跨站请求发送cookie
   2. **lax**：这个稍微宽松一点，大多数情况也是不发送第三方 Cookie，但是导航到目标网址的 Get 请求除外。
   3. **none**：请求会自动带上。

   还有一个属性 **Secure**，表示只在 HTTPS 协议加密传输，明文的 HTTP 会禁止发送，但 Cookie本身不是加密的，依旧是明文。

**cookie的缺点**

1. 容量缺陷：cookie大小一般只有 4kb，每个domain最多只能由 20 条cookie
2. 安全缺陷：以明文的形式保存在客户端，不能存储敏感信息，如果不设置 HttpOnly ，可以通过 js 获取。
3. 性能缺陷：cookie 紧跟域名，每次请求时都会带上cookie，随着请求数量的增多会造成性能浪费。但是可通过指定 domain 和 path 来解决。

#### HTTP 缓存控制

浏览器使用 HTTP 获取资源的成本较高，所以有必要把数据缓存起来，下次请求时尽可能地复用，这样可以有效避免多次请求应答的成本，节约网咯带宽，加快响应速度。

缓存可大致分为 **客户端缓存** 和 **服务端缓存**

**客户端缓存**

**服务器的缓存控制**

服务器标记资源有效期使用的头字段是 **Cache-Control**，里面的值 **max-age**，表示资源的有效期。



> 除了 Cache-Control 头字段外，还有 Expires 头字段，值是过期时间，表示在这个过期时间之前可以继续使用缓存，优先级要低于 Cache-Control。
>
> 由于Expires 的值是服务器的时间，而服务器和客户端的时间可能并不一致，所以这个过期时间可能就不准确。因此在 HTTP1.1 中被抛弃了。还有一个历史遗留字段 “Pragma: no-cache"，相当于 ”Cache-Control：no-cache“，除非为了兼容 HTTP1.0 否则不建议使用。



**注意：资源生存时长计算时间起点是服务端生成响应报文的时刻（即 Date 字段，也就是离开服务器的时刻），不是客户端收到报文时刻**。也就是说包含了在链路传输过程中所有节点停留的时长，如果 max-age = 5，由于网络状况较差，客户端收到报文的时候已经过去了3 秒，那么这个资源在客户端最多只能存活 2 秒。

除了 max-age，在响应报文中还能用其他属性来更精确得到指示浏览器如何使用缓存：

- **no_store**：表示不允许缓存。用于变化非常频繁的页面，如秒杀页面
- **no_cache**：这个字段与no_store 字段容易弄混，实际上不是允许缓存，而是**可以缓存**，只是每次在使用之前都需要向服务器验证是否可用。
- **must-revalidate**：他的意思是缓存不过期就可以使用，如果过期就需要去服务器验证

**浏览器的缓存控制**

有了缓存之后是否就可以直接用了呢？假如你在浏览器里点几次刷新按钮，会发现页面并没有被缓存。这是为什么呢？

其实不只是服务器可以发 **Cache-Control**，客户端也可以发送，也就是说请求-应答双方都可以用这个字段进行缓存控制，互相协商缓存的使用策略。

当你点击刷新的时候，浏览器会在请求头里加一个 **Cache-Control: max-age=0**，max-age=0意思要最新的数据，因此浏览器不会使用缓存，而是向服务器发送请求，服务器看到 max-age=0 ，也会生成最新的报文回复给浏览器。

**ctrl + F5** 强制刷新又是怎样的呢？其实就是 **Cache-Control: no_cache**，含义与 max-age=0，一样看后台服务器怎么理解，通常效果都是一样的。

条件请求

缓存没过期时可以直接使用，如果过期就要去服务器验证是否可用。常用头字段有 **If-Modified-Since** 和 **If-None-Match** 两个。

服务器第一次响应报文中会提供 **Last-Modified** 和 **Etag** 两个头字段，第二次请求时就会带上缓存的原值，验证资源是否是最新的。如果资源没有变，服务器会返回 **304**，表示缓存依旧有效，客户端只需要更新一下有效期就可以继续使用。

**Last-Modified** ：表示文件的最后修改时间

**Etag**：是服务器根据当前资源生成的一个唯一标识。这个字段是 **Last-Modified** 能够感知的单位是秒级，如果在一秒内修改了多次，那么是无法区分的；其次 如果资源修改时间更新了但是内容并没有变化，也会造成缓存失效。

**Etag 还有"强"，"弱"之分**。强 ETag 要求资源在字节级别必须完全相符，弱 ETag 在值前有个“W/”标记，只要求资源在语义上没有变化，但内部可能会有部分发生了改变（例如 HTML 里的标签顺序调整，或者多了几个空格）。

#### HTTP 代理

HTTP 基于“请求-应答”的模型，协议中只有两个互相通信的角色，一个是请求方（浏览器），另一个是应答方（服务器），但有特殊情况，就是代理服务器。**代理服务** 其实就是客户端和服务端通信链路中插入的一个中间环节，也是台服务器，对于客户端，表现为服务器，代源服务器响应请求；对于服务端，表现为客户端，代客户端发送请求，具有双重身份。

**代理服务作用**

1. **负载均衡**：由于在面向客户端时屏蔽了源服务器，客户端看到的只是代理服务器，背后有多少台源服务器，是哪些 IP 地址都是不知道的，因此由代理服务器掌握分发请求的大权，通过一些算法将请求合理的分散到不同的服务器，提高系统整体资源的利用率和性能。负载均衡的算法有：**轮询**，**随机**，**一致性哈希**等。
2. **安全防护**: 利用“心跳”等机制监控后端服务器，发现有故障就及时“踢出”集群，保证服务高可用；保护被代理的后端服务器，限制 IP 地址或流量，抵御网络攻击和过载；拦截上下行的数据，任意指定策略修改请求或者响应等
3. **内容缓存**：暂存复用服务器响应。

**代理相关头字段**

前面提到代理服务器隐藏了真实的客户端和服务端，那么如果双方想要获得这些原始信息该怎么办呢？

**Via** ：这个字段用来记录经过的代理服务器。当报文每经过一个代理节点，代理服务器就会把自身的信息（主机名或者域名）追加到字段的末尾，这样到达对端时就可以根据这个字段知道报文经过了哪些环节才到达目的地。

例如 

> 客户端 -> 代理1 -> 代理2 -> 服务器

服务器拿到的报文里 Via 字段的值为 proxy1,proxy2

客户端拿到的报文里 Via 字段的值就是 proxy2,proxy1

Via 字段只能知道客户端和服务端之间是否存在代理，还不能知道对方的真实身份。一般来说服务器的 IP 地址应该是保密的，关系到内网安全，一般不会让客户端知道，但是反过来服务端通常需要知道客户端真实 IP 地址。常用的两个头字段是 **”X-Forwarded-For"** 和 **“X-Real-IP"** 。

**X-Forwarded-For** : 这个字段与 ”Via" 类似，只不过它追加的信息不是代理主机名，而是请求方的 IP 地址，所以在字段最左边的就是客户端的地址。

**X-Real-IP**：另一种获取客户端真实 IP 的手段。它只记录客户端的 IP 地址，没有中间的代理信息。相当于 X-Forward-For 的简化版，如果客户端与服务器之间只有一个代理，那么 X-Forward-For 和 X-Real-IP 两个字段的值是一样的。

 **X-Forward-Host , X-Forward-Proto**：与 X-Real-IP 类似，只记录客户端请求的原始域名和协议名。

**代理协议**

有了 X-Forwarded-For 等头字段，服务器就可以拿到客户端准确的数据了。但是对于代理服务器来说操作 X-Forwarded-For 等头字段必须要解析 HTTP 头，成本比较高，会降低代理的转发性能。另一个问题是 X-Forwarded-For 等头必须修改原始报文，在有些情况写是不允许甚至是不可能的，比如（HTTPS通信被加密）

于是出现了专门的**代理协议（The PROXY protocal）**。

代理协议有 v1 和 v2 两个版本，v1 使用明文，v2使用二进制格式。

v1 版本只需要在 HTTP 报文前加一行 ASCII 码文本，相当于多了一个头

这一行文本其实非常简单，开头必须是“PROXY”五个大写字母，然后是“TCP4”或者“TCP6”，表示客户端的 IP 地址类型，再后面是请求方地址、应答方地址、请求方端口号、应答方端口号，最后用一个回车换行（\r\n）结束。

```
// PROXY + TCP4/TCP6 + 请求方地址 + 接收方地址 + 请求方端口号 + 接收方端口号
PROXY TCP4 1.1.1.1 2.2.2.2 55555 80\r\n
GET / HTTP/1.1\r\n
Host: www.xxx.com\r\n
\r\n
```

**缓存代理**

不仅客户端可以缓存，服务器也可以缓存，让请求不必走完整个后续处理过程，“就近”获得响应结果。

HTTP 服务器缓存功能主要由代理服务器来实现。

当代理服务器不缓存的时候，充当的只是一个中转站。加入缓存后就不一样了，代理服务器收到服务端发来的响应数据后，需要做两件事：一是将响应发给客户端，而是把报文缓存下来。下次再有同样的请求，代理服务器可以直接发送304或者缓存数据，不必再从源服务器获取，这样就降低了客户端的等待时间，也节省了源服务器的网络带宽。

代理服务器面向客户端和服务端，既可以使用客户端的缓存控制策略，也可以使用服务端的缓存控制策略。也就是说可以同时使用 **Cache-Control ** 的各种属性。但是代理服务器只是一个数据中转站，还需要新的 Cache-Control 属性对它进行约束.

**private和public**

**private** 表示缓存只能再客户端保存，不能放在代理上使用；**public** 表示缓存时公有的，谁都可以用。

**must-revalidate 和 proxy-revalidate**

缓存失效后的验证也需要分开。**must-revalidate** 表示只要过期就要去源服务器验证，**proxy-revalidate** 表示代理的缓存过期后去源服务器上验证，客户端只需要验证到代理这个环节就可以了

**s-maxage**

"s" 意思是 share ,只限定在代理的缓存能够存多久，客户端依旧使用 max-age

**no-transform**

代理有时候会对缓存下来的数据进行优化，比如把图片生成png, webp 等几种格式，方便今后的请求。“no-transform" 不允许这样做，不能对缓存数据进行改动。

**客户端缓存控制**

对于客户端新增了两个属性 **max-stale** 和 **min-fresh**

**max-stale** 表示代理上的缓存过期了也能接受，但不能过期太多，超过 x 秒后也不要；**min-fresh** 表示缓存必须有效，而且必须在 x 秒后也必须有效。

 **if-only-cached** 

表示只接受代理缓存的数据，不接受源服务器的响应，如果代理上没有缓存或者缓存过期，应该给客户端返回一个 **504 (Gateway Timeout)**

#### HTTPS

由于 HTTP 的 ”明文“、”不安全“的缺点，引入了新的 HTTPS 协议来保证通信安全。

> **什么样的通信才算是“安全”的？**
>
> 1. 机密性。指对数据保密
> 2. 完整性。指数据在传输过程中没有被篡改
> 3. 身份认证。指确认对方的真实身份
> 4. 不可否认。指不能否认发生的行为。

HTTPS 规定了新的协议名 **”HTTPS“**，默认端口号 **443**，它把 HTTP 下层传输协议替换成了 **SSL/TLS协议**。

**TLS** 由记录协议、握手协议、警告协议、变更密码规范协议、扩展协议等几个子协议组成，综合使用了对称加密、非对称加密、身份认证等许多密码学前沿技术。

浏览器和服务器在使用 TLS 建立连接时需要选择一组恰当的加密算法来实现安全通信，这些算法的组合被称为“密码套件”（cipher suite，也叫加密套件）。

密码套件命名格式很固定，基本的形式为：”密钥交换算法 +签名算法 + 对称加密算法 + 摘要算法“

> 例如：ECDHE-RSA-AES256-GCM-SHA384
>
> 这个密码套件表示：握手时使用 ECDHE 算法进行密钥交换，用 RSA 算法签名和身份验证，握手后的通信使用 AES256 对称算法，米密钥长度时 256，分组模式是 GCM，摘要算法用 SHA 384用于消息认证和产生随机数

##### **机密性**

实现机密性常用方法就是 ”加密“。加密前的消息叫做 **明文**，加密的钥匙叫做 **密钥**，明文加密后的乱码叫做 **密文**，使用密钥还原明文叫做 **解密**，加密解密的操作过程叫做 ”**加密算法**”

加密算法都是公开的，而算法使用的密钥是保密的。根据密钥的使用方式分为 **对称加密** 和 **非对称加密**

​	**对称加密**

​	加密和解密使用的密钥都是同一个密钥。

​	**非对称加密**

​	对称加密好像实现了机密性。但是如何把密钥安全的传递给对方呢？如果密钥被截获，那么通信也就毫无机密性可言。于是出现了非对称加密。

​	非对称加密采用了 2 个密钥，一个是 **公钥**，另一个是 **私钥**。公钥可以公开给任何人知道，而私钥必须严格保密。

​	公钥和私钥有个特别的单向性：**公钥加密的密文只能用私钥解密，私钥加密的密文只能用公钥解密**

​	由于黑客不知道私钥，所以无法知道公钥加密后的密文。

**非对称加密** 加密虽然没有 **”密钥交换“**的问题，但由于加密过程基于复杂的数学运算，运算速度很慢，与对称加密差了好几个量级，如果仅使用非对称加密，虽然实现了机密性，但是通信的速度太慢，实用性太差。

**混合加密**

最好的方法是将对称加密和非对称加密结合起来，也就是 **混合加密**的方式。

通信开始阶段使用非对称加密，解决密钥交换的问题。使用随机数产生对称算法使用的 **”会话密钥“**，再使用公钥加密，对方拿到密文后使用私钥解密得到会话密钥，这样就实现了密钥交换，后续就使用对称加密进行通信。

##### **完整性**

**混合加密** 实现了通信内容机密性，但是黑客可以通过收集足够多的密文，尝试修改，重组后发给网站，应为没有完整性保证，服务器只能照单全收，这样通过服务器的响应获取下一步线索，最后还是会破解出明文。

实现完整性主要靠 **摘要算法** ，也就是常说的 离散函数、哈希函数。

有了 **摘要算法**，只要再原文后附上它的摘要就可以保证内容的完整性。但是摘要算法不具有机密性，所以摘要和明文需要一起被加密。

**身份认证**

黑客也可以伪装成你向网站发送支付转账等消息，网站没有办法确认你的身份，就会有安全问题。所以需要保证通信双方身份的真实性，现实生活中解决身份认证的手段是签名和印章，只要在纸上签名或者印章，就表示这份文件确实是本人发出的而不是其他人。而这个签名和印章必须是本人持有，独一无二的，只要用这个东西就能证明自己的身份，这个东西就是非对称加密里的 **私钥**。

用 **私钥** 加上摘要算法就能实现 ”数字签名“，同时实现身份认证和不可否认。

**数字签名**的原理很简单，就是私钥加密，公钥解密。只要你和网站交换了公钥，就能使用 **”签名“** 和 **”验签“**来验证消息的真实性。

**数字证书和 CA**

前面所说因为谁都可以发布公钥，公钥的真实性怎么保证呢？也就是怎么证明这是你的或者是网站的公钥？

假如使用类似密钥交换的方式解决公钥认证的问题，那么只会陷入死循环，必须借助一个“外力”，找一个可以信任的第三方作为信任的起点，这个第三方就是 **CA（Cerificate Authority，证书认证中心）**。

**CA** 对公钥的签名认证也是有格式的，不能简单将公钥绑定在持有者身份上就完事了，，还要包含序列号，用途，颁发者，有效时间等，把它们打包再签名，形成 **数字证书**。

CA 也需要证明自己。小一点的 CA 可以让大 CA 签名认证，到链条的最后也就是 **Root CA**，只能自己证明自己，这就是 **自签名证书**，你必须相信否则整个证书信任链就走不下去了。

操作系统和浏览器都内置了各大 CA 的根证书，上网的时候只要服务器发过来它的证书，就可以验证证书里的签名，顺着证书链（Certificate Chain）一层层地验证，直到找到根证书，就能够确定证书是可信的，从而里面的公钥也是可信的。

#### HTTPS 建立连接

HTTP 协议里三次握手建立连接后，就可以发送 HTTP报文；但是 HTTPS 还需要另外一个 ”握手“ 的过程，在 TCP 上建立安全连接后在发送报文。

**TLS 1.2 版本**

1. **传统RSA连接**

   TCP 建立连接后，首先会发送 **Client Hello** 消息，也就是向服务器 “打招呼”。里面有客户端的版本号，支持的密码套件，还有一个 **随机数（Client Random）**，用于生成后续会话密钥。

   然后服务端回应 **Server Hello** 消息，把版本号确认一下，然后选择一种密码套件（RSA），将服务器生成的一个 **随机数（Server Random）**，一并发给对方，然后服务器为了验证自己的身份，将证书也发给了客户端。

   之后是 **Server Hello Done** 消息，表示我的消息就这些，”打招呼“完毕。

   客户端收到证书后开始走证书链逐级验证，验证服务器身份无误之后，根据密码套件生成 **pre-master**，这其实也是一个随机数。客户端发送一个 **Client Key Exchange** 消息， 将pre-master加密后发给服务器。

   这样双方都有 3个随机数，通过这三个随机数生成主密钥。主密钥生成后握手就快结束了，客户端会发一个 **Change Cipher Spec**，然后再发一个 **Finished** 消息，把之前的数据做一个 **摘要**，再加密一下，让服务端做验证。意思是之后通信就用这个密钥加密了，密钥对不对服务器再测一下。

   服务器也是同样的操作发送 **Change Cipher Spec** ， **Finished** 消息，双方验证加密解密，后续就使用加密后的 HTTP 请求和响应。

2. **ECDHE 连接**

   之前是传统的 RSA 握手过程，现在主流的TLS 握手过程使用的是 ECDHE 加密套件。

   与RSA大致流程相同，不同的是由于使用的 ECDHE 算法，服务器还会生成一个 **Server Params** ，这是 **椭圆曲线的公钥**，在发送证书后发送一个 **Server Key Exchange** 消息，里面就是Server Params，用来实现密钥交换算法，再加上自己的私钥签名认证。

   然后客户端按照密码套件的要求，也生成一个 **Client Params**，用 **Client Key Exchange** 消息发送给服务器。

   现在客户端和服务端都拿到了密钥交换算法的两个参数 **Server Params** 和 **Client Params**，通过 ECDHE 算法计算生成 **pre-master**，用 客户端随机数和服务端随机数加上这个 pre-master，就可以生成主密钥。

   主密钥也不是最终通信的会话密钥，还会用PRF算法扩展出更多密钥，比如客户端发送用的会话密钥，服务器发送用的会话密钥等等，避免只用一个密钥带来的安全隐患。

   与传统的RSA握手过程有两点不同：

   1.  RSA握手 **Client Key Change** 消息里面是 **pre-master**；ECDHE 握手则是 **密钥交换算法的参数**，pre-master由双方自己计算而来。
   2. ECDHE 算法可以不等服务端发送 **Finshed** 消息确认握手完毕，立即发送 HTTP 报文，节省了一个 消息往返时间的浪费。这个叫 **"TLS False Start"**，意思是 ”抢跑“，与 “TCP Fast Open” 有点像，都是不等连接完全建立就提前发送数据。 

**双向认证**

上面所说的是 **单向认证**，只验证了服务器的身份，客户端的身份还没认证。这是因为通常单向认证之后已经建立了安全通信，可以用账号密码等确认客户端的身份。

为了防止账号、密码被盗，有时候比如（网上银行）还会使用 U盾 给客户端颁发证书，**实现双向认证**。

双向认证流程没有太多变化，只是再 **Server Hello Done** 之后，**Client Key Exchange** 之前，客户端发送 **Client Certificate** 消息，将自己的证书发给服务器进行验证。

**TLS 1.3版本**

TLS1.2 版本已经是十几年前的的老协议，再安全和性能方面已经跟不上现在的互联网了。于是有了 TLS1.3版本。

TLS1.3版本的主要改进目标是 **兼容，安全，性能**

**兼容**

1.1 1.2版本出现了很多年，许多应用软件，代理商只认识老的记录格式，更新改造困难。为了区分 1.2 和 1.3版本，要用到新的 **扩展协议**。通过再记录头的末尾添加一系列扩展字段来增加新的功能。

在记录头的 **Version** 字段被兼容性固定的情况下，只要是 TLS 1.3协议，握手的 **"Hello"** 协议后就必须有 **”support_versions"** 字段，他标记了TLS的版本号。

**强化安全**

TLS 1.2 陆续被发现了很多漏洞和加密算法的弱点，因此 TLS1.3 版本修补了这些不安全的因素。

废除了多种算法后，TLS1.3 只保留了 AES, ChaCha20 算法，分组模式只能用 AEAD的 GCM、CCM 和 Poly1305，摘要算法只能使用 SHA256、SHA384，密钥交换算法只有 ECDHE 和 DHE，椭圆曲线也被“砍”到只剩 P-256 和 x25519 等 5 种。

> 这里还要特别说一下废除 RSA 和 DH 密钥交换算法的原因.
>
> 假设有这么一个很有耐心的黑客，一直在长期收集混合加密系统收发的所有报文。如果加密系统使用服务器证书里的 RSA 做密钥交换，一旦私钥泄露或被破解（使用社会工程学或者巨型计算机），那么黑客就能够使用私钥解密出之前所有报文的“Pre-Master”，再算出会话密钥，破解所有密文。
>
> 而 ECDHE 算法在每次握手时都会生成一对临时的公钥和私钥，每次通信的密钥对都是不同的，也就是“一次一密”，即使黑客花大力气破解了这一次的会话密钥，也只是这次通信被攻击，之前的历史消息不会受到影响，仍然是安全的。
>
> 以现在主流的服务器和浏览器在握手阶段都已经不再使用 RSA，改用 ECDHE，而 TLS1.3 在协议里明确废除 RSA 和 DH 则在标准层面保证了“前向安全”

**提升性能**

HTTPS 建立连接时需要再进行 TLS 握手，再 1.2版本中会多花 2 个RTT的消息往返时间，可能会导致几十甚至几百毫秒的延迟，在移动网络中延迟还会更严重。

TLS 1.3 密码套件大幅简化后，就不必再向以前那样走复杂的流程了。TLS1.3 压缩了以前的“Hello”协商过程，删除了“Key Exchange”消息，把握手时间减少到了“1-RTT”，效率提高了一倍。

具体的做法还是利用了扩展。客户端在“Client Hello”消息里直接用“**supported_groups**”带上支持的曲线，比如 P-256、x25519，用 “**key_share**” 带上曲线对应的客户端公钥参数，用“**signature_algorithms**”带上签名算法。

服务器收到后在这些扩展里选定一个曲线和参数，再用 **“key_share”** 扩展返回服务器这边的公钥参数，就实现了双方的密钥交换，后面的流程就和 1.2 基本一样了

#### HTTPS 性能优化

HTTPS 连接”慢“通常指的时刚开始建立连接那段时间。除了TLS 握手带来的网络耗时外，产生密钥交换的临时公私钥对（ECDHE）、验证证书、非对称加密处理 “pre-master"

那有哪些手段可以进行优化呢？

**硬件优化**

1. 更快的 CPU

2. SSL加速卡：加解密时调用它的API，让专门的硬件来做非对称加密，分担 CPU 的计算压力。但是也有缺点：升级慢，支持算法有限，不能灵活制定解决方案
3. SSL加速服务器：用专门的服务器集群来彻底“卸载”TLS 握手时的加密解密计算，性能自然要比单纯的“加速卡”要强大的多。

**软件优化**

软件优化比较简单，就是尽量将正在使用的软件升级到最新版本，由于软件在更新版本的时候都会做性能优化、修复错误，因此优化效果最容易达到。

**协议优化**

尽量采用 TLS1.3 版本，它大幅简化了握手过程，相比TLS1.2 少了 1 RTT，而且更加安全。

**会话复用**

会话复用分两种：

一种叫 **”Session ID“**：就是客户端和服务器首次连接后各自保存一个会话的 ID 号，内存里存储主密钥和其他相关的信息。当客户端再次连接时发一个 ID 过来，服务器就在内存里找，找到就直接用主密钥恢复会话状态，跳过证书验证和密钥交换，只用一个消息往返就可以建立安全通信。

另一种叫 **"Session Ticket"**: 它有点类似 HTTP 的 Cookie，存储的责任由服务器转移到了客户端，服务器加密会话信息，用“New Session Ticket”消息发给客户端，让客户端保存。

重连的时候，客户端使用扩展“**session_ticket**”发送“Ticket”而不是“Session ID”，服务器解密后验证有效期，就可以恢复会话，开始加密通信。不过“Session Ticket”方案需要使用一个固定的密钥文件（ticket_key）来加密 Ticket，为了防止密钥被破解，保证“前向安全”，密钥文件需要定期轮换，比如设置为一小时或者一天。

**预共享密钥**

原理和“Session Ticket”差不多，但在发送 Ticket 的同时会带上应用数据（Early Data），免去了 1.2 里的服务器确认步骤，这种方式叫“**Pre-shared Key**”，简称为“PSK”。

但“PSK”也不是完美的，它为了追求效率而牺牲了一点安全性，容易受到“重放攻击”（Replay attack）的威胁。黑客可以截获“PSK”的数据，像复读机那样反复向服务器发送。

解决的办法是只允许安全的 GET/HEAD 方法，在消息里加入时间戳、“nonce”验证，或者“一次性票证”限制重放。

>"Session ID" 和 "Session Ticket" 这两种会话复用的方式在 TLS1.3中均已经被废除了，只能使用 PSK 实现会话复用